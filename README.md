Here, you can learn how to deal with a big text when feeding it to a large language model. The employed LLM is efficient for English but works effectively for other languages, such as French.
However, you can change the pre-trained model based on your text language to get higher accuracy (if needed).
I have employed "bert-base-uncased" here.
Do not forget to install the required libraries based on the "import" commands.Â 
Also, you can update " max_tokens " to a suitable size for feeding the LLM (if needed).

Please read my article here:
https://medium.com/@mehrdad.al.2023/how-do-we-cope-with-long-documents-when-we-want-to-process-them-with-large-language-models-f0fd0c154e4d

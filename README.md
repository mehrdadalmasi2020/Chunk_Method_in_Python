Here, you can find how to deal with a big text when feeding it to a Large Language Model. The provided code is efficient for the English language. BTW, it can work properly for other languages such as French. 
However, you can change the pre-trained model based on your text language to get higher accuracy (if needed).
I have employed "bert-base-uncased" here. 
Do not forget to install the required libraries based on the "import" commands. Also, "max_tokens" is something that you need to update based on the suitable size for feeding the LLM.
